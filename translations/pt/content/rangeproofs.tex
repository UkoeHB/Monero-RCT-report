\chapter{Provas de Domínio}
\label{chapter:range_proofs}

Um problema com compromissos additivos é o de valores negativos. Sejam $C(a_1)$, $C(a_2)$, $C(b_1)$, $C(b_2)$ e pretende-se provar que :
\[(a_1 + a_2) - (b_1 + b_2) = 0\]
Uma solução é :
\[a_1 = 6, a_2 = 5, b_1 = 21, b_2 = -10\]

%One problem with additive commitments is that, if we have commitments $C(a_1)$, $C(a_2)$, $C(b_1)$, and $C(b_2)$ and we intend to use them to prove that $(a_1 + a_2) - (b_1 + b_2) = 0$, then those commitments would still apply if one value in the equation were `negative'.

%For instance, we could have $a_1 = 6$, $a_2 = 5$, $b_1 = 21$, and $b_2 = -10$.\vspace{.175cm}
\begin{flalign*}
    && (6 + 5) - (&21 + -10) = 0&\\
     \intertext{\quad \quad \quad \quad \quad em que} && 21G + -10G = 21G + (&l-10)G = (l + 11)G = 11G&
\end{flalign*}

Visto que $-10 = l-10$, efectivamente foram creados $l$ mais Moneroj do que existiam nas entradas (mais de 7.2x10$^{74}$ xmr).


%Bulletproofs start here
A solução para isto é provar que cada montante de saída está dentro de um certo domínio (de 0 a $2^{64}-1$). 
O esquema de provas que é utilizado chama-se {\em Bulletproofs} (Benedikt B\"{u}nz {\em et al.}\cite{Bulletproofs_paper}).

\section{Assinaturas em anel Borromean}
\label{sec:borromean}

Seja o seguinte compromisso ao montante $b$ :\vspace{.175cm}
\[C_{a} = x G + b H \]
\vspace{.175cm}

Primeiro faz-se uma partição aleatória de x tal que :\vspace{.175cm}
\[x = \sum_{i=0}^{k-1} x_i \]
\vspace{.175cm}

Segundo descreve-se b em termos binários :\vspace{.175cm}
\[b = \sum_{i=0}^{k-1} b_i 2^i \]
\vspace{.175cm}

O compromisso $C_a$ define-se então como :\vspace{.175cm}
\[C_{a} = \sum_{i=0}^{k-1} C_{i} = \sum_{i=0}^{k-1} x_i G + b_i 2^i H \]
\vspace{.175cm}

O objectivo aqui é de provar que o compromisso $C_a$ é válido. Mas $C_a$, só por si não prova algo pois é somente um ponto de CE. A prova de domínio advém de que cada $C_i$ satisfaz um certo constrangimento na assinatura to tipo {\em Borromean}. 

Se cada $C_i$ é :

\vspace{.175cm}
\[C_{i} = x_i G + b_i 2^i H \]
\vspace{.175cm}

então, se $b_i$ = 1:
\vspace{.175cm}
\[x_i G = C_{i} - b_i 2^i H \]
\vspace{.175cm}

e se $b_i$ = 0 :

\vspace{.175cm}
\[x_i G = C_{i} \]
\vspace{.175cm}

Como tal, a chave privada que é usada é o escalar $x_i$, e o seu ponto de CE $x_i G$. 
Há que provar este contrangimento sem revelar $b_i$. 
\newpage
Para isso fixa-se $C_i$ e $C_i - 2^i H$, como argumentos para a prova de domínio.

Seja que $b_i$ = 0, então o caso base é:
\begin{align*}
\alpha=r()\\
\beta_1=r()\\
\omega = H_s(\alpha G)\\
\psi_g = \beta_1 G + \omega (\bold{C_i - 2^i H})\\
\Psi_g = H_s(\psi_g)\\
\lambda = r()\\
\beta_0=\alpha-x_i*\lambda\\
\end{align*}

agora passa-se $\Psi_g$, $\beta_0$, $\beta_1$ e $\lambda$ para o verificador.  

\begin{align*}
\mu=\beta_0 G + \lambda \bold{C_i}\\
\mu= (\alpha-x_i*\lambda) G + \lambda \bold{C_i}\\
\mu= \alpha G-\lambda (x_i G) + \lambda \bold{C_i}\\ 
\mu= \alpha G\\
\theta= H_s(\mu)\\
\psi_c = \beta_1 G + \theta (\bold{C_i - 2^i H})\\
\Psi_c = H_s(\psi_c)\\
%eeComp = dumber25519.hash_to_scalar(LC2)
\end{align*}

Note-se que $\Psi_g$ é igual a $\Psi_c$ e como tal a prova é válida.\newline
Em que $r()$ é um escalar aleatório no corpo finito $F_l$. E $H_s(\alpha G)$ é um certo escalar aleatório, que resulta do argumento dado á função {\em hash} $H_s(\alpha G)$ (aqui $\alpha G$, $H_s$ aceita qualquer tipo de dados como argumento).   
O operador binário * é uma multiplicação entre dois escalares no corpo finito $F_l$. E $\alpha G$ por exemplo é adicionar o ponto de CE $G$, consigo próprio $\alpha$ vezes.  
\newpage
Seja que $b_i$ = 1, então o caso base é:
\begin{align*}
\alpha=r()\\
\psi_g = \alpha G\\
\Psi_g = H_s(\psi_g)\\
\lambda = r()\\
\beta_0=r()\\
\phi=\beta_0 G + \lambda \bold{C_i}\\
\epsilon = H_s(\phi)\\
\beta_1 = \alpha-x_i*\epsilon\\
\end{align*}

agora passa-se $\Psi_g$, $\beta_0$, $\beta_1$ e $\lambda$ para o verificador.  

\begin{align*}
\mu=\beta_0 G + \lambda \bold{C_i}\\
\theta= H_s(\mu)\\
\psi_c = \beta_1 G + \theta (\bold{C_i - 2^i H})\\
\psi_c = (\alpha-x_i*\epsilon) G + \theta (\bold{C_i - 2^i H})\\
\psi_c = \alpha G - \epsilon(x_i G)
                  + \theta (\bold{C_i - 2^i H})\\
\psi_c = \alpha G - H_s(\beta_0 G + \lambda \bold{C_i})(x_i G)\\
                 + H_s(\beta_0 G + \lambda \bold{C_i})(\bold{C_i - 2^i H})\\
\psi_c = \alpha G\\ 
\Psi_c = H_s(\psi_c)\\
\end{align*}

Note-se que $\Psi_g$ é igual a $\Psi_c$ e como tal a prova é válida.

As provas apresentadas funcionam, porque :

os argumentos precalculados, $C_i - 2^i H$ e $C_i$ só permitem que b seja 1 ou 0.
Á parte de que a geração de uma assinatura deste tipo só se define para que b seja um bit. Mesmo que o algoritmo seja alterado para tentar fazer assinaturas com outros valores para b, as equações dadas não se resolveriam na parte da verificação.
Quem verifica sabe de certeza que o provador usou um bit mas não sabe se esse bit tem o valor de 0 ou 1.

Para mais, este caso base cobre todos os índices de um vector de 64 bits.
visto que a verificação é sempre a mesma :
\begin{align*}
\mu=\beta_0 G + \lambda C_i\\
\theta= H_s(\mu)\\
\psi_c = \beta_1 G + \theta (C_i - 2^i H)\\
\Psi_c = H_s(\psi_c)\\
%eeComp = dumber25519.hash_to_scalar(LC2)
\end{align*}

O bob podia gerar cada $C_i$ e repetir o processo descrito em cima. A alice para cada $C_i$ gerava $C_i -2^i H$, recebia também os argumentos para cada prova $\Psi_g$, $\beta_0$, $\beta_1$ e $\lambda$, e verificava que a prova é válida.
A alice sabe portanto que :

\vspace{.175cm}
\[C_{a} = \sum_{i=0}^{k-1} C_{i} \]
\vspace{.175cm}
\newline
e tem a certeza que b é um vector de 64 bits, ou seja que o montante está dentro do domínio de 0 a $2^{64} -1$. Estas provas constituem uma assinatura em anel, mas não se trata própriamente de um anel, não é um processo circular. Para mais veja-se \cite{DangerousFreedom1984} .\footnote{No código em {\em python}, evita-se enviar $\lambda$, e usa-se $\Psi_g$ como parámetro para a verificação final, bem como variável supostamente aleatória! Ou seja $\Psi_g$ é utilizado para calcular $\Psi_c$ (através de bbs0 e bbs1) como resultado final... O que não deixa de ser elegante! }
\newline\newline\newline
É aparente que $2^i$ pode ser qualquer $k_i>0 \in F_l$.
Seja que :
\vspace{.175cm}
\[b = \sum_{i=1}^{m} b_i k_i \]
\vspace{.175cm}
\newline
Os termos de $2^i$ são conhecidos pelo verificador de antemão, como tal não são transmitidos pelo provador. Se fosse $k_i$ em vez de $2^i$, o provador teria de enviar mais $m$ escalares em $F_l$. pois então o constrangimento passaria a ser :

Se cada $C_i$ é :

\vspace{.175cm}
\[C_{i} = x_i G + b_i k_i H \]
\vspace{.175cm}

então, se $b_i$ = 1:
\vspace{.175cm}
\[x_i G = C_{i} - b_i k_i H \]
\vspace{.175cm}

e se $b_i$ = 0 :

\vspace{.175cm}
\[x_i G = C_{i} \]
\vspace{.175cm}


De seguida faz-se exactamente o mesmo processo descrito em cima, e as provas acontecem á mesma. Em termos de $2^i$, com 64 bits o valor máximo é $(2^{64})-1$. Em que cada montante $b$ nesse domínio é equiprovável. Ou seja existem $2^{64}$ combinações distintas possíveis. No caso de serem $m$ escalares, o constrangimento adicional teria de ser válido : 

\[\sum_{i=1}^{m} k_i \leq (2^{64})-1 \]

Se isto não fosse o caso o verificador nem se dava ao trabalho de olhar para as provas. E o número de combinações distintas possíveis seria $2^m$. Se $m=2$, imagine-se $k_1=2$ e $k_2=3$. O bob envia 5 xmr para a alice e quem verifica só sabe que o montante enviado é zero, dois, trés ou cinco. O que seria mau em termos de privacidade. 

\section{Bulletproofs}
\label{sec:bullet_proofs}

\centerline{{\it Sou mais rápido quando me mexo.}}
\centerline{\quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad {\it Sundance}}

\subparagraph{Em português : provas de bala.\newline}

Á partida não se percebe sequer como é que alguém chega a descobrir o algoritmo descrito anteriormente, das assinaturas borromeanas. Não se esplica aqui também todos os vectores de ataque contra tais assinaturas ou se as assinaturas borromeanas para o seu custo de comunicação, são as mais compactas. O leitor que pensa portanto como é que se chega a tal coisa? Ou também : "não se pode forjar tais assinaturas?" permanece sem explicação dada. Não só isso mas mais, o que se segue é muito mais complicado e será explicado em termos verbatim. Ou seja quem segue o método consegue compreender o porque dele funcionar, mas não como é que se chega a tal coisa, nem como se forja uma tal prova, ou onde ele poderá falhar se implementada mal.

Se v está entre 0 e $2^{64} - 1$  \newline
Primeiro passa-se v para a sua representação binária :\newline $\underline{a}_L \leftarrow bits$ v \newline
Ou seja : \newline $v = \langle\underline{a}_L, \underline{2}^n\rangle$ \newline
em que $\underline{2}^n = \{2^0, 2^1, 2^2, ..., 2^{n-1}\}$
Depois põe-se dois constrangimentos adicionais :
\begin{align*}
v = \langle\underline{a}_L, \underline{2}^n\rangle\\
\underline{a}_R = \underline{a}_L - \underline{1}\\
\underline{a}_L \circ \underline{a}_R  = 0
\end{align*}

Depois faz-se o seguinte :

\begin{align*}
v = \langle\underline{a}_L, \underline{2}^n\rangle\\
0 = \langle\underline{a}_L - \underline{1} - \underline{a}_R, \underline{y}^n\rangle\\
0 = \langle\underline{a}_L \circ \underline{a}_R, \underline{y}^n\rangle
\end{align*}

Note-se que isto são tudo afirmações equivalentes, mas a introdução de $\underline{y}^n$, já é : "excepto uma negligível probabilidade de falhar" (enp).
Porque $\underline{y}^n = \{y^0, y^1, y^2, ..., y^{n-1}\}$, com qualquer $\underline{c} = \{c_0, c_1, c_2, ...c_{n-1}\}$ (neste caso $\underline{c} = \underline{a}_L - \underline{1} - \underline{a}_R$ ou $\underline{c} = \underline{a}_L \circ \underline{a}_R$) constitui o polinómio : 
\begin{align*}
F(y) = c_0 y^0 + c_1 y^1 + c_2 y^2 + ... + c_{n-1} y^{n-1}   
\end{align*}

E este polinómio tem no máximo $n - 1$ raízes ($F(y) = 0$). Em que $\underline{c} = \underline{0}$ é uma delas. A probabilidade de um atacante encontrar outro $\underline{c}'$ tal que $F(y) = 0$ é : $n/l$, e como tal negligível.\newline

Continua-se então a representar o mesmo de outra forma ainda :

\begin{align*}
vz^2 = \langle\underline{a}_L, \underline{2}^n\rangle z^2\\
0z = \langle\underline{a}_L - \underline{1} - \underline{a}_R, \underline{y}^n\rangle z\\
0 = \langle\underline{a}_L \circ \underline{a}_R, \underline{y}^n\rangle
\end{align*}

o que depois de muita manipulação resulta na seguinte equação em que $\underline{a}_L$ e $\underline{a}_R$ se encontram de lados opostos no produto interno :  \newline

\begin{equation}
z^2 v + \delta(y,z) = \langle\underline{a}_L - \underline{1}z, \underline{y}^n \circ (\underline{a}_R + \underline{1}z) + z^2 \underline{2}^n\rangle 
\end{equation}

\begin{align*}
\delta(y,z) = (z - z^2)  \langle \underline{1}, \underline{y}^n \rangle - z^3 \langle \underline{1}, \underline{2}^n \rangle
\end{align*}

Para ver como se chega ás equações anteriores veja-se o apêndice \ref{appendix:nota}. Enfim á primeira vista o que se conseguio até agora foi representar que v está constrangido segundo ás trés regras iniciais, de uma forma altamente elaborada.\newline
O provador não pode enviar o lado direito da equação (5.1) ao verificador senão este fica a saber os bits de $v$.

Como tal há que ofuscar $\underline{a}_L$ e $\underline{a}_R$ :\newline

$(\underline{a}_L + \underline{\dot{s}}_L ) - \underline{1}z\enspace *^5\\
\underline{y}^n \circ ((\underline{a}_R + \underline{\dot{s}}_R) + \underline{1}z) + z^2 \underline{2}^n\enspace *^6$


Note-se que o que se alcanço agora foi algo diferente, tanto que : 

\begin{align*}
z^2 v + \delta(y,z) \neq \langle(\underline{a}_L + \underline{\dot{s}}_L) - \underline{1}z, \underline{y}^n \circ ((\underline{a}_R + \underline{\dot{s}}_R) + \underline{1}z) + z^2 \underline{2}^n\rangle 
\end{align*}
\newline
Define-se então o conseguido anteriormente como : \newline
$\underline{l}_0 = \underline{a}_L - \underline{1}z\\
\underline{r}_0 = \underline{y}^n \circ (\underline{a}_R + \underline{1}z) + z^2 \underline{2}^n$

ou seja :
\begin{align*}
z^2 v + \delta(y,z) = \langle \underline{l}_0, \underline{r}_0 \rangle = t_0
\end{align*}

e também os factores ofuscantes : \newline
$\underline{l}_1 = \underline{\dot{s}}_L\\
\underline{r}_1 = \underline{y}^n \circ \underline{\dot{s}}_R$

força-se então novas igualdades : $*^2$$*^3$ \newline
$\underline{l}(x) = \underline{l}_0 + \underline{l}_1 x\\
\underline{r}(x) = \underline{r}_0 + \underline{r}_1 x$

Finalmente : $*^4$
\begin{align*}
t(x) = \langle \underline{l}(x), \underline{r}(x)\rangle = t_0 + t_1 x + t_2 x^2
\end{align*}

O que se obtém como tal, é um polinómio que em $t_0$ se compromete a $V$. O que o provador faz é enviar um número de variáveis ao verificador, que fazem parte de um circuito aritmético. Em que o conjunto dessas variáveis, nesse sistema, implica que $v$ satisfaz a condição do domínio requerido.\newline

Calculam-se também os coefficientes de t(x): $*^1$
\[t(x) = \langle (\underline{l}_0 + \underline{l}_1 x), (\underline{r}_0 + \underline{r}_1 x) \rangle = \langle \underline{l}_0, \underline{r}_0 \rangle + \langle \underline{l}_0, \underline{r}_1 x \rangle + \langle \underline{l}_1 x, \underline{r}_0 \rangle + \langle \underline{l}_1 x, \underline{r}_1 x \rangle\]
\newline
$t_0 = \langle \underline{l}_0, \underline{r}_0 \rangle\\
t_1 x = \langle \underline{l}_0, \underline{r}_1 x \rangle + \langle \underline{l}_1 x, \underline{r}_0 \rangle = \langle \underline{l}_0, \underline{r}_1 \rangle x + \langle \underline{l}_1, \underline{r}_0 \rangle x = (\langle \underline{l}_0, \underline{r}_1 \rangle + \langle \underline{l}_1, \underline{r}_0 \rangle ) x\\
t_2 x^2 = \langle \underline{l}_1, \underline{r}_1 \rangle x^2$

\newpage
$G$, $H$, $\underline{G}$, $\underline{H}$ \hspace*{\fill} \ce{^{0}_{\ }\bot[init]} \newline
$V = \gamma G + v H$ \hspace*{\fill} \ce{^{1}_{\ }\bot_U(V)} \newline
$\underline{a}_L \leftarrow bits$ v \newline
$\underline{a}_R = \underline{a}_L - \underline{1}$ \newline 
$\dot{\alpha} \leftarrow R()$ \newline
$A = \langle\underline{G},\underline{a}_L\rangle + \langle\underline{H},\underline{a}_R\rangle + \alpha G \hspace*{\fill}\ce{^{2}_{\ }\bot_U(A)}$ \newline
$\dot{\rho} \leftarrow R()$ \newline
$\underline{\dot{s}}_L \leftarrow R()$ \newline
$\underline{\dot{s}}_R \leftarrow R()$ \newline
$S = \langle\underline{G},\underline{\dot{s}}_L\rangle + \langle\underline{H},\underline{\dot{s}}_R\rangle + \dot{\rho} G$\hspace*{\fill} \ce{^{3}_{\ }\bot_U(S)} \newline
$y\leftarrow \ce{^{4}_{\ }\bot_C()}$, $y^{-1}$ \newline
$z\leftarrow \ce{^{5}_{\ }\bot_C()}$
\begin{align*}
(t_0, t_1, t_2)*^1
\end{align*}
$\dot{\tau_1} \leftarrow R()$ \newline
$\dot{\tau_2} \leftarrow R()$ \newline
$T_1 = t_1 H + \dot{\tau_1} G $ \hspace*{\fill} $\ce{^{6}_{\ }\bot_U(T_1)}$ \newline
$T_2 = t_2 H + \dot{\tau_2} G $ \hspace*{\fill} $\ce{^{7}_{\ }\bot_U(T_2)}$ \newline
$x\leftarrow \ce{^{8}_{\ }\bot_C()}$ \newline
$\tau_x = \dot{\tau_1}x + \dot{\tau_2}x^2 + \gamma z^2$ \hspace*{\fill}$\ce{^{9}_{\ }\bot_U(\tau_x)}$ \newline
$\mu = x\dot{\rho} + \dot{\alpha}$ \hspace*{\fill}$\ce{^{10}_{\ }\bot_U(\mu)}$ \newline
\begin{align*}
(\underline{l}(x) = \underline{l}_0 + \underline{l}_1 x)*^2\\
(\underline{r}(x) = \underline{r}_0 + \underline{r}_1 x)*^3
\end{align*}
\newline
\begin{align*}
t(x) = \langle \underline{l}(x), \underline{r}(x) \rangle = (t_0 + t_1 x + t_2 x^2)*^4 
\end{align*}\hspace*{\fill} $\ce{^{11}_{\ }\bot_U(t(x))}$ \newline
$x_{ip}\leftarrow \ce{^{12}_{\ }\bot_C()}$\newline
$U = x_{ip} H$\newline\newline\newline
IP\leftarrow $\{\underline{G}$, $\underline{H'}$, $U$, $\underline{l}(x)$, $\underline{r}(x)\}$ 

O símbolo $\bot$ significa um traslado. Ou seja durante este processo sequencial, este traslado devolve hashes. Estas por sua vez são transformadas em escalares ou pontos de CE. Em que $\bot_U()$ é renovar o estado do traslado e $\bot_C()$ devolve um desafio. O $j$ em $\ce{^{j}_{\ }\bot}$ marca o estado do traslado, como base, no tempo. Vectores são sublinhados como 
$\underline{a}$ para escalares ou $\underline{G}$ para pontos de CE. Para simbolizar variáveis livres usa-se um ponto, acima da letra($\dot{\alpha}$, $\dot{S}}_L$, ...), que recebe um escalar ou ponto de CE aleatório da função R(). Estes valores como sendo livres, têm que ser enviados para o verificador. Ao invés de variáveis como $\underline{G}$, que apesar de serem aleatórias, são valores públicos e bem definidos, e como tal podem e são precalculados pelo verificador de forma independente. Note-se que os vectores têm sempre 64 bits. O protocolo do produto interno, IP, reduz o tamanho dos vectores 
á ordem de $\log_2(64)$. E para isso acontecer, o provador constroi os seguintes circuitos aritméticos, em que o primeiro trata do lado esquerdo da equação (5.1) e o segundo do lado direito :

\newline

\newcommand{\verteq}{\rotatebox{90}{$\,$}}
\newcommand{\verteqq}{\rotatebox{90}{$\,=$}}
\newcommand{\equalto}[2]{\underset{\scriptstyle\overset{\mkern4mu\verteq}{#2}}{#1}}
\newcommand{\equaltoo}[2]{\underset{\scriptstyle\overset{\mkern4mu\verteqq}{#2}}{#1}}

$\equalto{t(x) H}{+} = \equalto{z^2 v H}{+} + \equalto{\delta(y,z) H}{+} + \equalto{t_1 x H}{+} + \equalto{t_2 x^2 H}{+}$

$\equaltoo{\enspace\tau_x G}{\ }  \enspace\enspace= \equaltoo{\gamma z^2 G}{\ }\enspace + \equaltoo{0G}{\ }\quad +\enspace \equaltoo{\dot{\tau}_1 x G}{\ } + \equaltoo{\dot{\tau}_2 x^2 G}{\ }$

$\quad\quad\quad = \underbrace{z^2 V + \delta(y, z) H}_{\text{público}} \enspace+ x T_1 +\enspace x^2 T_2$

\newline

As mentes ávidas ao lerem isto dizem logo :"Ah e tal mas $T_1$ e $T_2$ pode ser qualquer coisa, até porque está ali o $\dot{\tau}_1$, isso são tudo variáveis aleatórias... Como é que isso tem alguma expressão sobre $v$?"$\enspace$ Primeiro t(x) não pode ser directamente igual a $t_0$, pois como $z^2$ e $\delta(y, z)$ são públicos, o verificador conseguiria extraír $v$. Assim $t_1$ e $t_2$ são factores ofuscantes estruturados para manter t(x) secreto ao provador. Mais adiante na altura da $\it{execução}$, irá ser necessário que $t(x) = \langle \underline{l}(x), \underline{r}(x) \rangle$, mais uma razão para que t(x) não possa ser só igual a $t_0$. O que torna $T_1$ e $T_2$ necessários ao circuito. Aqui "público" significa a estrutura formal, y e z têm de ser extraídos do traslado pelo verificador.

\newline

$\equalto{\langle \underline{l}(x),\underline{G}\rangle}{+} = \enspace\equalto{\langle\underline{G},\underline{a}_L\rangle}{+} + \enspace\enspace\equalto{\langle\underline{G},\underline{\dot{s}}_L\rangle}{+} + \quad\equalto{\langle -z\underline{1},\underline{G}\rangle}{+}$  $*^5$

$\equalto{\langle \underline{r}(x),\underline{H'}\rangle}{+}  = \equalto{\langle\underline{H},\underline{a}_R\rangle}{+} + \equalto{x\langle\underline{H},\underline{\dot{s}}_R\rangle}{+} + \equaltoo{\langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle}{\ }$  $*^6$ 

$\equaltoo{\quad\mu G}{\ } \quad\quad= \enspace\enspace \equaltoo{\dot{\alpha} G}{\ } \quad +\quad \equaltoo{x \dot{\rho} G}{\ }$ 

$\quad\quad\quad\quad\enspace=\enspace\enspace\enspace A \quad\quad+\quad x S \quad+\quad \underbrace{\langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle}_{\text{público}}$

\newline


Em que $\underline{H'} = \underline{y}^{-n}\circ\underline{H} \leftrightarrow \underline{H} = \underline{y}^{n}\circ\underline{H'}$\newline
Esta é uma das partes mais elegantes, o provador não possui $\underline{y}^{n}$ á sua disposição para inserir no circuito aritmético. Portanto usa $\underline{H'}$ para fazer os compromissos de forma implícita/indirecta! Ou seja o provador tem de inserir $\underline{y}^{n}$ contra $\underline{a}_R$ e $\underline{\dot{s}}_R$, só que por causa da forma como o método é implementado nessa altura da comunicação entre provador e verificador, $\underline{y}^{n}$ ainda não existia para o provador, veja-se na página anterior como $y$ só existe depois do compromisso a $A$ e $S$. 

Imagine-se que o provador envia :

$t(x)$, $\tau_x$, $\underline{l}(x)$,$\underline{r}(x)$, $\mu$, $T_1$, $T_2$, $A$, $S$

ao verificador. Note-se que o verificador só através de $\underline{l}(x)$ e $\underline{r}(x)$ não consegue extraír $t_0$, por causa dos factores ofuscantes $\underline{\dot{s}}_L$ e $\underline{\dot{s}}_R$.  

\subsection{Verificação}
\label{sec:bullet_ver}

Agora se o verificador receber as duas equações anteriores, ele consegue provar que V está no domínio requerido. Mas por agora ainda estamos numa comunicação com dois vectores de 64 bits, $\underline{l}(x)$ e $\underline{r}(x)$ : \newline


$t(x) H + \tau_x G + \langle \underline{l}(x),\underline{G}\rangle + \langle \underline{r}(x),\underline{H'}\rangle + \mu G=\\= z^2 V + \delta(y, z) H \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle$
\newline\newline
a sorte é que :
\begin{equation}
\langle \underline{l}(x),\underline{G}\rangle + \langle \underline{r}(x),\underline{H'}\rangle + \langle \underline{l}(x), \underline{r}(x)\rangle U = P_0 - \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{equation}
\newline\hspace*{\fill} em que o $k=\log_{2}64=6$

o que depois implica :

$t(x) H + \tau_x G + P_0 - \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k  + \mu G=\\= \langle \underline{l}(x), \underline{r}(x)\rangle U + z^2 V + \delta(y, z) H \enspace+ x T_1 +\enspace x^2 T_2 + A + x{S} + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle$

o provador aproveita o facto de que :

\begin{align*}
t(x) = \langle \underline{l}(x), \underline{r}(x) \rangle
\end{align*}
e só envia t(x) :\newline

\marginnote{pow!}
$t(x) H + \bold{\tau}_x G + P_0 - \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k + \mu G=\\= t(x) U + z^2 V + \delta(y, z) H \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle$
$\hspace*{\fill} \blacksquare$

ou seja nem sequer se enviam os $u_{j}^{-2}$ nem os $u_{j}^{2}$.

o que para o custo de comunicação ainda é melhor, enviam-se então 2*6 + 9, escalares e pontos de CE:

$t(x)$, $\tau_x$, $a$, $b$, $\mu$, $T_1$, $T_2$, $A$, $S$, $L_{1,2,3,...6}$ e $R_{1,2,3,...6}$ 


Em vez de 2*64 pelo menos, como nas assinaturas borromeanas. 
\newpage
\subsubsection{mais detalhes do provador}
\label{sec:bullet_detalhes}

Aqui continua o processo do provador, no protocolo do produto interno IP. Têm-se que $P_k$ é o argumento de começo para o protocolo :\newline
$P_k = \langle \underline{l}_k(x),\underline{G}_k\rangle + \langle \underline{r}_k(x),\underline{H'}_k\rangle + \langle \underline{l}_k(x), \underline{r}_k(x)\rangle U$

Aqui $isto^{\rightarrow}$ significa do início do vector até metade, e $isto^{\leftarrow}$ significa do fim do vector até metade.

Enquanto $n>1$\newline
$L_k = \langle \underline{l}^{\rightarrow}_{k}(x),\underline{G}^{\leftarrow}_{k}\rangle + \langle \underline{r}^{\leftarrow}_{k}(x),\underline{H'}^{\rightarrow}_{k}\rangle + \langle \underline{l}^{\rightarrow}_{k}(x), \underline{r}^{\leftarrow}_{k}(x)\rangle U$

$R_k = \langle \underline{l}^{\leftarrow}_{k}(x),\underline{G}^{\rightarrow}_{k}\rangle + \langle \underline{r}^{\rightarrow}_{k}(x),\underline{H'}^{\leftarrow}_{k}\rangle + \langle \underline{l}^{\leftarrow}_{k}(x), \underline{r}^{\rightarrow}_{k}(x)\rangle U$

\hspace*{\fill} $\ce{^{13}_{\ }\bot_U(L_k)}$ \newline
\hspace*{\fill} $\ce{^{14}_{\ }\bot_U(R_k)}$ \newline
$u_{k}\leftarrow \ce{^{15}_{\ }\bot_C()}$\newline

\begin{align*}
\underline{l}_{k-1}(x) = u_{k} \underline{l}_{k}^{\rightarrow}(x) + u^{-1}_{k} \underline{l}_{k}^{\leftarrow}(x)\\
\underline{r}_{k-1}(x) = u^{-1}_{k} \underline{r}_{k}^{\rightarrow}(x) + u_{k} \underline{r}_{k}^{\leftarrow}(x)\\
\underline{G}_{k-1} = u^{-1}_{k} \underline{G}_{k}^{\rightarrow} + u_{k} \underline{G}_{k}^{\leftarrow}\\
\underline{H'}_{k-1} = u_{k} \underline{H'}_{k}^{\rightarrow} + u^{-1}_{k} \underline{H'}_{k}^{\leftarrow}\\
\end{align*}
$n=n/2$

se $n=1$ devolve-se $a$ e $b$.

Em que o 13 em $\ce{^{13}_{\ }\bot_U()}$ marca só a primeira ronda. O verificador não se irá perder, e no passo n° 13 do seu traslado, irá colher o mesmo. Passamos agora á magia em volta de $P_k$. Primeiro é notável como os $u_{j}$'s podem ser quaisquer valores em $F_l$. Para chegar a $P_k$, começa-se a partir de  $P_{k-1}$:\newline  
$
P_{k-1} = \langle \underline{l}_{k-1}(x),\underline{G}_{k-1}\rangle + \langle \underline{r}_{k-1}(x),\underline{H'}_{k-1}\rangle + \langle \underline{l}_{k-1}(x), \underline{r}_{k-1}(x)\rangle U
$

\begin{align*}
P_{k-1} = \langle u_{k} \underline{l}_{k}^{\rightarrow}(x) + u_{k}^{-1} \underline{l}_{k}^{\leftarrow}(x), u_{k}^{-1} \underline{G}_{k}^{\rightarrow} + u_{k} \underline{G}_{k}^{\leftarrow}\rangle +\\ \langle u_{k}^{-1} \underline{r}_{k}^{\rightarrow}(x) + u_{k} \underline{r}_{k}^{\leftarrow}(x), u_{k} \underline{H'}_{k}^{\rightarrow} + u_{k}^{-1} \underline{H'}_{k}^{\leftarrow}\rangle +\\\langle u_{k} \underline{l}_{k}^{\rightarrow}(x) + u_{k}^{-1} \underline{l}_{k}^{\leftarrow}(x), u_{k}^{-1} \underline{r}_{k}^{\rightarrow}(x) + u_{k} \underline{r}_{k}^{\leftarrow}(x)\rangle U
\end{align*}
\newline
\begin{align*}
P_{k-1} = 
\langle \cancel{u_{k}} \underline{l}_{k}^{\rightarrow}(x), \cancel{u_{k}^{-1}} \underline{G}_{k}^{\rightarrow}\rangle + \langle u_{k} \underline{l}_{k}^{\rightarrow}(x), u_{k} \underline{G}_{k}^{\leftarrow}\rangle \\
\langle \cancel{u_{k}^{-1}} \underline{l}_{k}^{\leftarrow}(x), \cancel{u_{k}} \underline{G}_{k}^{\leftarrow}\rangle + \langle u_{k}^{-1} \underline{l}_{k}^{\leftarrow}(x), u_{k}^{-1} \underline{G}_{k}^{\rightarrow}\rangle +\\ 
\langle \cancel{u_{k}^{-1}} \underline{r}_{k}^{\rightarrow}(x), \cancel{u_{k}} \underline{H'}_{k}^{\rightarrow}\rangle + \langle u_{k}^{-1} \underline{r}_{k}^{\rightarrow}(x), u_{k}^{-1} \underline{H'}_{k}^{\leftarrow}\rangle +\\
\langle \cancel{u_{k}} \underline{r}_{k}^{\leftarrow}(x), \cancel{u_{k}^{-1}} \underline{H'}_{k}^{\leftarrow}\rangle + \langle u_{k} \underline{r}_{k}^{\leftarrow}(x), u_{k} \underline{H'}_{k}^{\rightarrow}\rangle +\\
\langle \cancel{u_{k}} \underline{l}_{k}^{\rightarrow}(x), \cancel{u_{k}^{-1}} \underline{r}_{k}^{\rightarrow}(x) \rangle U + \langle u_{k} \underline{l}_{k}^{\rightarrow}(x), u_{k} \underline{r}_{k}^{\leftarrow}(x)\rangle U +\\
\langle \cancel{u_{k}^{-1}} \underline{l}_{k}^{\leftarrow}(x), \cancel{u_{k}} \underline{r}_{k}^{\leftarrow}(x)\rangle U + \langle u_{k}^{-1} \underline{l}_{k}^{\leftarrow}(x), u_{k}^{-1} \underline{r}_{k}^{\rightarrow}(x)\rangle U
\end{align*}
\newline

$
P_{k-1} = \newline
\langle  \underline{l}_{k}^{\rightarrow}(x),  \underline{G}_{k}^{\rightarrow}\rangle$ \quad\quad$+ u_{k}^2 \langle \underline{l}_{k}^{\rightarrow}(x), \underline{G}_{k}^{\leftarrow}\rangle\newline$ 
$\langle  \underline{l}_{k}^{\leftarrow}(x),  \underline{G}_{k}^{\leftarrow}\rangle$ \quad\quad$+ u_{k}^{-2}\langle \underline{l}_{k}^{\leftarrow}(x), \underline{G}_{k}^{\rightarrow}\rangle + $\newline
$\langle \underline{r}_{k}^{\rightarrow}(x),  \underline{H'}_{k}^{\rightarrow}\rangle$ \quad$+ u_{k}^{-2}\langle \underline{r}_{k}^{\rightarrow}(x), \underline{H'}_{k}^{\leftarrow}\rangle + $\newline
$\langle  \underline{r}_{k}^{\leftarrow}(x),  \underline{H'}_{k}^{\leftarrow}\rangle$ \quad$+ u_{k}^2 \langle \underline{r}_{k}^{\leftarrow}(x), \underline{H'}_{k}^{\rightarrow}\rangle +$\newline
$\langle  \underline{l}_{k}^{\rightarrow}(x),  \underline{r}_{k}^{\rightarrow}(x) \rangle U + u_{k}^2 \langle \underline{l}_{k}^{\rightarrow}(x), \underline{r}_{k}^{\leftarrow}(x)\rangle U +$\newline
$\underbrace{\langle  \underline{l}_{k}^{\leftarrow}(x), \underline{r}_{k}^{\leftarrow}(x)\rangle U}_{P_k} + \underbrace{u_{k}^{-2} \langle \underline{l}_{k}^{\leftarrow}(x), \underline{r}_{k}^{\rightarrow}(x)\rangle U}_{u_{k}^{2}L_k + u_{k}^{-2}R_k}$
$\marginnote{clik!}$
$\newline$
E como tal possibilita-se a seguinte recursão : \newline
$
P_k = P_{k-1} - (u_{k}^{2}L_k + u_{k}^{-2}R_k)\newline
P_{k-1} = P_{k-2} - (u_{k-1}^{2}L_{k-1} + u_{k-1}^{-2}R_{k-1})\newline
.\newline
.\newline
P_{1} = P_{0} - (u_{1}^{2}L_{1} + u_{1}^{-2}R_{1})\newline
$
tal que : \newline
\begin{align*}
P_k = P_0 - \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k\\
P_{0} = \ce{^{0}_{\ }\underline{l}(x)}\ce{^{0}_{\ }\underline{G}} + \ce{^{0}_{\ }\underline{r}(x)}\ce{^{0}_{\ }\underline{H'}} + \ce{^{0}_{\ }\underline{l}(x)}\ce{^{0}_{\ }\underline{r}(x)}U 
\end{align*}

\newline
Em que $\ce{^{0}_{\ }\underline{l}(x)}$ e $\ce{^{0}_{\ }\underline{r}(x)}$ são só dois escalares (em Monero representa-se isto como $a$ e $b$ respectivamente na transacção).

\subsubsection{O verificador e o fim da batalha}
\label{sec:bullet_fim}

Enquanto que $\ce{^{0}_{\ }\underline{l}(x)}$ e $\ce{^{0}_{\ }\underline{r}(x)}$ têm de ser transmitidos ao verificador, $\ce{^{0}_{\ }\underline{G}}$ e $\ce{^{0}_{\ }\underline{H'}}$ pode ser, e é calculado independentemente pelo verificador. A recursão de $G$ :
\begin{align*}
\underline{G}_{k-1} = u^{-1}_{k} \underline{G}_{k}^{\rightarrow} + u_{k} \underline{G}_{k}^{\leftarrow}
\end{align*}

Implica que, por exemplo, se o $\underline{G}_{k}$ inicial tivesse só 8 elementos (em vez de 64):

\begin{align*}
\begin{bmatrix}
\ce{^{\ }_{0}\underline{G}_{3}}u_{3}^{-1} \\
\ce{^{\ }_{1}\underline{G}_{3}}u_{3}^{-1} \\
\ce{^{\ }_{2}\underline{G}_{3}}u_{3}^{-1} \\
\ce{^{\ }_{3}\underline{G}_{3}}u_{3}^{-1} \\
\ce{^{\ }_{4}\underline{G}_{3}}u_{3} \\
\ce{^{\ }_{5}\underline{G}_{3}}u_{3} \\
\ce{^{\ }_{6}\underline{G}_{3}}u_{3} \\
\ce{^{\ }_{7}\underline{G}_{3}}u_{3} \\
\end{bmatrix}\rightarrow
\begin{bmatrix}
(\ce{^{\ }_{0}\underline{G}_{2}}=\ce{^{\ }_{0}\underline{G}_{3}}u_{3}^{-1} + \ce{^{\ }_{4}\underline{G}_{3}}u_{3})u_{2}^{-1} \\
(\ce{^{\ }_{1}\underline{G}_{2}}=\ce{^{\ }_{1}\underline{G}_{3}}u_{3}^{-1} + \ce{^{\ }_{5}\underline{G}_{3}}u_{3})u_{2}^{-1} \\
(\ce{^{\ }_{2}\underline{G}_{2}}=\ce{^{\ }_{2}\underline{G}_{3}}u_{3}^{-1} + \ce{^{\ }_{6}\underline{G}_{3}}u_{3})u_{2} \\
(\ce{^{\ }_{3}\underline{G}_{2}}=\ce{^{\ }_{3}\underline{G}_{3}}u_{3}^{-1} + \ce{^{\ }_{7}\underline{G}_{3}}u_{3})u_{2} \\
\end{bmatrix}\rightarrow
\begin{bmatrix}
\ce{^{\ }_{0}\underline{G}_{1}}u_{1}^{-1} \\
\ce{^{\ }_{1}\underline{G}_{1}}u_{1} \\
\end{bmatrix}\rightarrow
\begin{bmatrix}
\ce{^{0}_{\ }\underline{G}} \\
\end{bmatrix}
\end{align*}
\newline\newline\newline\newline
O padrão que $\ce{^{\ }_{2}\underline{G}_{3}}$ segue por exemplo é :
\begin{align*}
\ce{^{\ }_{2}\underline{G}_{3}}u_{3}^{-1}u_{2}u_{1}^{-1}  
\end{align*}
\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad porque 2 = $010_2$ \newline
E $\ce{^{\ }_{7}\underline{G}_{3}}u_{3}u_{2}u_{1}$,  porque 7 = $111_2$ ... \newline

E genericamente para $\ce{^{\ }_{i}\underline{G}_{k}}$, segue-se : \newline
\begin{align*}
\ce{^{\ }_{i}\underline{G}_{k}} \rightarrow \ce{^{\ }_{i}\underline{G}_{k}}u_{k}^{b(i,k)}u_{k-1}^{b(i,k-1)}u_{k-2}^{b(i,k-2)}...u_{1}^{b(i,1)}
\end{align*}

\begin{align*}
 b(i,j)=
 \begin{cases} 
      \text{-1, se o j-ésimo bit de i for 0} \\
      \text{ 1, se o j-ésimo bit de i for 1} \\
 \end{cases}
\end{align*}

O que acontece então é que o verificador forma um vector $\underline{\phi}$ com 64 elementos tal que cada elemento :

\begin{align*}
 \underline{\phi}[i]=\prod_{m=1}^{k} u_{m}^{b(i,m)}
\end{align*}

O mesmo é feito para $\ce{^{0}_{\ }\underline{H'}}$, em que o verificador forma outro vector $\underline{\varphi}$ tal que : 

\begin{align*}
 \underline{\varphi}[i]=\prod_{m=1}^{k} u_{m}^\overline{b(i,m)}
\end{align*}

em que :

\begin{align*}
 \overline{b(i,m)}=
 \begin{cases} 
      \text{-1, se o j-ésimo bit de i for 1} \\
      \text{ 1, se o j-ésimo bit de i for 0} \\
 \end{cases}
\end{align*}

\newpage
$
G, H, \underline{G}, \underline{H} \hspace*{\fill} \ce{^{0}_{\ }\bot[init]} \newline
\hspace*{\fill} \ce{^{1}_{\ }\bot_U(V)} \newline
\hspace*{\fill} \ce{^{2}_{\ }\bot_U(A)} \newline
\hspace*{\fill} \ce{^{3}_{\ }\bot_U(S)} \newline
y\leftarrow \ce{^{4}_{\ }\bot_C()}, y^{-1} \newline
z\leftarrow \ce{^{5}_{\ }\bot_C()} \newline
$
\begin{align*}
\delta(y,z) = (z - z^2)  \langle \underline{1}, \underline{y}^n \rangle - z^3 \langle \underline{1}, \underline{2}^n \rangle
\end{align*}
$
\hspace*{\fill} \ce{^{6}_{\ }\bot_U(T_1)} \newline
\hspace*{\fill} \ce{^{7}_{\ }\bot_U(T_2)} \newline
x\leftarrow \ce{^{8}_{\ }\bot_C()} \newline
\hspace*{\fill}\ce{^{9}_{\ }\bot_U(\tau_x)} \newline
\hspace*{\fill}\ce{^{10}_{\ }\bot_U(\mu)} \newline
\hspace*{\fill}\ce{^{11}_{\ }\bot_U(t(x))} \newline
x_{ip}\leftarrow \ce{^{12}_{\ }\bot_C()} \newline
$

$k=6$\newline
enquanto $k \geq 1$\newline
$\hspace*{\fill}\ce{^{13}_{\ }\bot_U(L_k)}$ \newline
$\hspace*{\fill}\ce{^{14}_{\ }\bot_U(R_k)}$ \newline
$u_k\leftarrow \ce{^{15}_{\ }\bot_C()}$ \newline
$k=k-1$

Agora o verificador está armado com tudo o que precisa para fazer a verificação final. Voltamos então á equação (5.1) e simplificamos:\newline

\begin{align*}
t(x) H + \bold{\tau}_x G + P_0 - \sum_{j=1}^{k} u_{j}^{-2}L_k + u_{j}^{2}R_k + \mu G=\\= t(x) U + z^2 V + \delta(y, z) H \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle
\end{align*}
$
\newline
$
\begin{align*}
t(x) H - t(x) U - \delta(y, z) H + \bold{\tau}_x G + a\ce{^{0}_{\ }\underline{G}} + b\ce{^{0}_{\ }\underline{H'}} + abU + \mu G=\\= z^2 V \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle 
\\+ \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}
$
\newline
$
\begin{align*}
(t(x) - \delta(y, z)) H - t(x) U + \bold{\tau}_x G + a\ce{^{0}_{\ }\underline{G}} + b\ce{^{0}_{\ }\underline{H'}} + abU + \mu G=
\\= z^2 V \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n,\underline{H'}\rangle + \langle -z\underline{1},\underline{G}\rangle 
\\+ \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}
$
\newline
$
\begin{align*}
(t(x) - \delta(y, z)) H - t(x) U + \bold{\tau}_x G + abU + \mu G=\\=
z^2 V \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n - b\underline{\varphi},\underline{H'}\rangle + \langle -z\underline{1} - a\underline{\phi},\underline{G}\rangle
\\ + \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}
$
\newline
$
\begin{align*}
(t(x) - \delta(y, z)) H - t(x) x_{ip} H + (\tau_x + \mu) G + ab x_{ip} H =\\= z^2 V \enspace+ x T_1 +\enspace x^2 T_2 + A + x S + \langle z\underline{y}^n + z^2\underline{2}^n - b\underline{\varphi},\underline{H'}\rangle + \langle -z\underline{1} - a\underline{\phi},\underline{G}\rangle 
\\+ \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}
$
\newline
$
\begin{align*}
((t(x) - \delta(y, z)) - ((t(x) - ab)x_{ip})) H =
\\= z^2 V + (-\tau_x - \mu) G + x T_1 + x^2 T_2 + A + x S 
\\+ \langle z\underline{y}^n + z^2\underline{2}^n - b\underline{\varphi},\underline{H'}\rangle \\+ \langle -z\underline{1} - a\underline{\phi},\underline{G}\rangle 
\\+ \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}

\newline
Aqui usa-se $\underline{H'} = \underline{y}^{-n}\circ\underline{H} \leftrightarrow \underline{H} = \underline{y}^{n}\circ\underline{H'}$ .

\begin{align*}
(0, 1) =
z^2 V + (-\tau_x - \mu) G + x T_1 + x^2 T_2 + A + x S
\\+ ((\delta(y, z) - t(x)) + ((t(x) - ab)x_{ip})) H 
\\+ \langle z + y^{-n}\circ(z^2\underline{2}^n - b\underline{\varphi}),\underline{H}\rangle 
\\+ \langle -z\underline{1} - a\underline{\phi},\underline{G}\rangle
\\+ \sum_{j=1}^{k} u_{j}^{2}L_k + u_{j}^{-2}R_k
\end{align*}

Se esta equação passa, então $0 \leq v \leq 2^{64} - 1$ 


%(and also explained in \cite{adam-zero-to-bulletproofs,dalek-bulletproofs-notes}).\footnote{It's conceivable that with several outputs in a legitimate range, the sum of their amounts could roll over and cause a similar problem. However, when the maximum output is much smaller than $l$ it takes a huge number of outputs for that to happen. For example, if the range is 0-5, and l = 99, then to counterfeit money using an input of 2, we would need $5 + 5 + …. + 5 + 1 = 101 \equiv 2 \pmod{99}$, for 21 total outputs. In Monero $l$ is about 2\^{}189 times bigger than the available range, which means a ridiculous 2\^{}189 outputs to counterfeit money.} Given the involved and intricate nature of Bulletproofs, it is not elucidated in this document. Moreover we feel the cited materials adequately present its concepts.\footnote{Prior to protocol v8 range proofs were accomplished with Borromean ring signatures, which were explained in the first edition of Zero to Monero \cite{ztm-1}.}

%The Bulletproof proving algorithm\marginnote{src/ringct/ rctSigs.cpp {\tt proveRange- Bullet- proof()}} takes as input output amounts $b_t$ and commitment masks $y_t$, and outputs all $C^b_t$ and an $n$-tuple aggregate proof $\Pi_{BP} = (A, S, T_1, T_2, \tau_x, \mu, \mathbb{L}, \mathbb{R}, a, b, t)$\footnote{Vectors $\mathbb{L}$ and $\mathbb{R}$ contain $\lceil \textrm{log}_2(64 \cdot p) \rceil$ elements each. $\lceil$ $\rceil$ means the log function is rounded up. Due to their construction, some Bulletproofs use `dummy outputs' as padding to ensure $p$ plus the number of dummy outputs is a power of 2. Those dummy outputs can be generated during verification, and are not stored with the proof data.}\footnote{The variables in a Bulletproof are unrelated to other variables in this document. Symbol overlap is merely coincidental. Note that group elements $A, S, T_1, T_2, \mathbb{L},$ and $\mathbb{R}$ are multiplied by 1/8 before being stored, then multiplied by 8 during verification. This ensures they are all members of the $l$ sub-group (recall Section \ref{elliptic_curves_section}).}. That single proof is used to prove all output amounts are in range at the same time, as aggregating them greatly reduces space requirements (although it does increase the time to verify).\footnote{It turns out multiple separate Bulletproofs can be `batched'\marginnote{rct/ringct/ bulletproofs.cc {\tt bulletproof\_ VERIFY()}} together, which means they are verified simultaneously. Doing so improves how long it takes to verify them, and currently in Monero Bulletproofs are batched on a per-block basis, although there is no theoretical limit to how many can be batched together. Each transaction is only allowed to have one Bulletproof.} The verification algorithm takes as input all $C^b_t$, and $\Pi_{BP}$, and outputs {\tt true} if all committed amounts are in the range 0 to $2^{64} - 1$.

%The $n$-tuple $\Pi_{BP}$ occupies $(2 \cdot \lceil \textrm{log}_2(64 \cdot p) \rceil + 9) \cdot 32$ bytes of storage.
